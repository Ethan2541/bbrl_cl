save_best: False

logger:
      classname: bbrl.utils.logger.TFLogger
      log_dir: ./sac_logs/
      verbose: False
      every_n_seconds: 10

algorithm:
      seed:
            train: 335
            eval: 983
            q: 123
            explorer: 456
            torch: 789
      n_envs: 8
      n_steps_train: 32
      n_steps: 300_000
      eval_interval: 5000
      nb_evals: 10
      buffer_size: 1e6
      batch_size: 256
      learning_starts: 10000
      tau_target: 0.05
      max_grad_norm: 0.5
      discount_factor: 0.95
      entropy_mode: "auto" # "auto" or "fixed"
      init_entropy_coef: 2e-7

gym_env:
      env_name: Pendulum-v1

actor_optimizer:
      classname: torch.optim.Adam
      lr: 1e-3

critic_optimizer:
      classname: torch.optim.Adam
      lr: 1e-3

entropy_coef_optimizer:
      classname: torch.optim.Adam
      lr: 1e-3

policy_agent:
      classname: bbrl_cl.agents.SubspaceActionAgent
      hidden_size: 32
      input_dimension: nil
      output_dimension: nil
      start_steps: 0

      n_initial_anchors: 1
      dist_type: flat
      refresh_rate: 1.
      resampling_policy: False
      repeat_alpha: 100

critic_agent:
      classname: bbrl_cl.agents.agent.AlphaCritic
      hidden_size: 256
      obs_dimension: nil
      action_dimension: nil
      n_anchors: 1


alpha_search:
      classname: bbrl_cl.algorithms.AlphaSearch
      params:
            n_estimations: 1024
            n_rollouts: 32
            n_validation_steps: 200
            seed: 0

visualization:
      num_points: 40